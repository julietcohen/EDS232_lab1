---
title: "lab1c_ferret"
output: html_document
---

## Lab 1c. Species Distribution Modeling - Decision Trees

### 1 Setup

```{r}
# global knitr chunk options
knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE)

# load packages
librarian::shelf(
  caret,       # m: modeling framework
  dplyr, ggplot2 ,here, readr, 
  pdp,         # X: partial dependence plots
  ranger,      # m: random forest modeling
  rpart,       # m: recursive partition modeling
  rpart.plot,  # m: recursive partition plotting
  rsample,     # d: split train/test data
  skimr,       # d: skim summarize data table
  vip)         # X: variable importance

# options
options(
  scipen = 999,
  readr.show_col_types = F)
set.seed(42)

# graphical theme
ggplot2::theme_set(ggplot2::theme_light())

# paths
dir_data    <- here("ferret_data/sdm")
pts_env_csv <- file.path(dir_data, "pts_env.csv")

# read data
pts_env <- read_csv(pts_env_csv)
d <- pts_env %>% 
  select(-ID) %>%                   # not used as a predictor x
  mutate(
    present = factor(present)) %>%  # categorical response
  na.omit()    # drop rows with NA, there were 6 in this dataset

skim(d)
# skim is an alternative to summary()
```

## 1.1 Split data into training and testing

```{r}
# create training set with 80% of full data
d_split  <- rsample::initial_split(d, prop = 0.8, strata = "present")
# d_split class is not df, it is an intermediate obj that will be fed into the function training()

# could have also used the function initial_time_split() which uses the first proportion of the data set and second portion rather than drawing random sample for the split

# the next step is to use the subsequent function to initial_split(), which is training(), which requires the input to be an rsplit obj
d_train  <- rsample::training(d_split)
# contains both 0's and 1's

# table 
# show number of rows present is 0 vs 1
table(d$present)
```

## Decision Trees

### 2.1 Partition, depth = 1

```{r}
# rpart() stands for "recursive partitioning and regression trees", this function runs a rpart model running every column to predict presence of the species, with the control argument specifying criteria for splits to occur at each node, such as cp denoting that there is no minimum complexity (model simplicity achieved), and the minimum number of observations in any terminal node
# run decision stump model
mdl <- rpart(
  present ~ ., data = d_train, 
  control = list(
    cp = 0, minbucket = 5, maxdepth = 1))
mdl
```

```{r}
# plot tree 
par(mar = c(1, 1, 1, 1))
rpart.plot(mdl)
```
## 2.2 Partition, depth = default

```{r}
# decision tree with defaults
mdl <- rpart(present ~ ., data = d_train)
mdl
```

```{r}
rpart.plot(mdl)

# plot complexity parameter
plotcp(mdl)

# rpart cross validation results
mdl$cptable
```

## 2.3 Feature Interpretation

```{r}
# caret cross validation results
mdl_caret <- train(
  present ~ .,
  data       = d_train,
  method     = "rpart",
  trControl  = trainControl(method = "cv", number = 10),
  tuneLength = 20)

ggplot(mdl_caret)
```

```{r}
vip(mdl_caret, num_features = 40, bar = FALSE)
```

```{r}
# Construct partial dependence plots
# I changed the variable for pred.var argument from one ben had included to wc_alt
p1 <- partial(mdl_caret, pred.var = "lat") %>% autoplot()
p2 <- partial(mdl_caret, pred.var = "WC_alt") %>% autoplot()
p3 <- partial(mdl_caret, pred.var = c("lat", "WC_alt")) %>% 
  plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, 
              colorkey = TRUE, screen = list(z = -20, x = -60))
class(mdl_caret)
# Display plots side by side
gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```
## 3 Random Forests

3.1 Fit
```{r}
# number of features
n_features <- length(setdiff(names(d_train), "present"))

# fit a default random forest model
mdl_rf <- ranger(present ~ ., data = d_train)

# get out of the box RMSE
(default_rmse <- sqrt(mdl_rf$prediction.error))
```

## 3.2 Feature Interpretation

```{r}
# re-run model with impurity-based variable importance
mdl_impurity <- ranger(
  present ~ ., data = d_train,
  importance = "impurity")

# re-run model with permutation-based variable importance
mdl_permutation <- ranger(
  present ~ ., data = d_train,
  importance = "permutation")
p1 <- vip::vip(mdl_impurity, bar = FALSE)
p2 <- vip::vip(mdl_permutation, bar = FALSE)

gridExtra::grid.arrange(p1, p2, nrow = 1)
```















